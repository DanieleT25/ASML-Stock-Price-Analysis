{
  "hash": "2c3ac2d3b1997e1b44638ba18d551a43",
  "result": {
    "engine": "knitr",
    "markdown": "---\nformat: html\nexecute:\n  fig-width: 7\n  fig-height: 4\nknitr:\n  opts_chunk:\n    out.width: \"100%\"\n---\n\n# Volatility Analysis\n\n\n\nIn the previous chapter, we established that ASML returns exhibit a conditional mean behavior closely resembling a Random Walk, making directional forecasting ineffective. However, financial time series are characterized by a \"stylized fact\" known as **volatility clustering**: large changes tend to be followed by large changes, and small changes by small changes. This implies that while the *sign* of the return is unpredictable, its *magnitude* (risk) follows a recognizable pattern.\n\nThe objective of this chapter is to model and forecast the conditional variance to quantify the risk associated with the asset. To achieve this, we adopt a structured modeling framework:\n\n1. **Detection of ARCH Effects:** We verify the presence of conditional heteroskedasticity through the analysis of squared returns' autocorrelation (**ACF**) and formal statistical tests such as the **ARCH-LM Test**.\n2. **Asymmetry Testing:** We investigate whether the volatility reacts differently to positive versus negative shocks (leverage effect) using the **Sign Bias Test**, **Negative Size Bias Test**, **Positive Size Bias Test** and **Joint Effect**.\n3. **Model Estimation & Selection:** We estimate and compare three classes of models to capture different volatility dynamics: **GARCH (Standard)** and  **GJR-GARCH & E-GARCH**.\n4. **Forecasting & Evaluation:** We assess the predictive power of the models using error metrics suitable for volatility (e.g., **RMSE** and **QLIKE**) and a visual comparison of the estimated conditional variance over time.\n5. **Risk Management Application:** Finally, we translate the volatility forecasts into a practical risk metric by computing and plotting the **Value at Risk (VaR)**, a standard tool for quantifying potential losses in extreme market scenarios.\n\n\n## Exploratory Volatility Analysis\n\nLet's conduct a visual inspection of the squared log-returns $(r^2_t)$ and absolute log-returns $(|r_t|)$, while raw returns typically show no correlation (as established in the previous chapter), their squared or absolute versions often exhibit strong persistence.\n\n::: {.panel-tabset}\n\n### Squared Returns\n\n::: {.cell}\n\n```{.r .cell-code}\nfig_sq <- plot_ly(data = log_returns, x = ~Date, y = ~Squared, type = 'scatter',\n  mode = 'lines', name = 'Squared Returns', line = list(color = 'darkred', width = 1))\n\nfig_sq <- layout(\n  fig_sq,\n  title = \"ASML Squared Log-Returns\",\n  xaxis = list(title = \"Date\"),\n  yaxis = list(title = \"Squared Log Return\"),\n  shapes = list(\n    list(\n      type = \"line\",\n      x0 = min(log_returns$Date),\n      x1 = max(log_returns$Date),\n      y0 = 0, \n      y1 = 0,\n      line = list(color = \"black\", width = 1)\n    )\n  )\n)\n\nfig_sq\n```\n\n::: {.cell-output-display}\n![ASML Squared Daily Log-Returns](03-volatility-analysis_files/figure-pdf/plot-squared-returns-1.pdf){fig-pos='H' width=100%}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacf_sq <- acf(log_returns$Squared, plot = FALSE, lag.max = 30)\npacf_sq <- pacf(log_returns$Squared, plot = FALSE, lag.max = 30)\n\nci <- qnorm((1 + 0.95)/2)/sqrt(length(log_returns$Squared))\n\ndf_acf_sq <- data.frame(\n  lag = as.numeric(acf_sq$lag)[-1],\n  acf = as.numeric(acf_sq$acf)[-1])\n\ndf_pacf_sq <- data.frame(\n  lag = as.numeric(pacf_sq$lag),\n  pacf = as.numeric(pacf_sq$acf))\n\nfig_acf_sq <- plot_ly(df_acf_sq, x = ~lag, y = ~acf, type = 'bar', name = 'ACF',\n  marker = list(color = '#1f77b4')) %>%\n  \n  add_segments(x = min(df_acf_sq$lag), xend = max(df_acf_sq$lag), y = ci, yend = ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %>%\n  \n  add_segments(x = min(df_acf_sq$lag), xend = max(df_acf_sq$lag), y = -ci, yend = -ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %>%\n  \n  layout(yaxis = list(title = \"ACF\"))\n\nfig_pacf_sq <- plot_ly(df_pacf_sq, x = ~lag, y = ~pacf, type = 'bar', name = 'PACF',\n  marker = list(color = '#ff7f0e')) %>%\n  \n  add_segments(x = min(df_pacf_sq$lag), xend = max(df_pacf_sq$lag), y = ci, yend = ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %>%\n  \n  add_segments(x = min(df_pacf_sq$lag), xend = max(df_pacf_sq$lag), y = -ci, yend = -ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %>%\n  \n  layout(yaxis = list(title = \"PACF\"))\n\nsubplot(fig_acf_sq, fig_pacf_sq, nrows = 1, margin = 0.05, titleY = TRUE) %>%\n  layout(title = \"Squared Returns: Autocorrelation & Partial Autocorrelation\", \n  margin = list(t = 50))\n```\n\n::: {.cell-output-display}\n![Squared Returns ACF and PACF](03-volatility-analysis_files/figure-pdf/acf-pacf-squared-1.pdf){fig-pos='H' width=100%}\n:::\n:::\n\n\n### Absolute Returns\n\n::: {.cell}\n\n```{.r .cell-code}\nfig_sq <- plot_ly(data = log_returns, x = ~Date, y = ~Abs, type = 'scatter',\n  mode = 'lines', name = 'Absolute Returns', line = list(color = 'darkred', width = 1))\n\nfig_sq <- layout(\n  fig_sq,\n  title = \"ASML Absolute Log-Returns\",\n  xaxis = list(title = \"Date\"),\n  yaxis = list(title = \"Absolute value Log Return\"),\n  shapes = list(\n    list(\n      type = \"line\",\n      x0 = min(log_returns$Date),\n      x1 = max(log_returns$Date),\n      y0 = 0, \n      y1 = 0,\n      line = list(color = \"black\", width = 1)\n    )\n  )\n)\n\nfig_sq\n```\n\n::: {.cell-output-display}\n![ASML Absolute Daily Log-Returns ](03-volatility-analysis_files/figure-pdf/plot-absolute-value-returns-1.pdf){fig-pos='H' width=100%}\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacf_abs <- acf(log_returns$Abs, plot = FALSE, lag.max = 30)\npacf_abs <- pacf(log_returns$Abs, plot = FALSE, lag.max = 30)\n\nci <- qnorm((1 + 0.95)/2)/sqrt(length(log_returns$Abs))\n\ndf_acf_abs <- data.frame(\n  lag = as.numeric(acf_abs$lag)[-1],\n  acf = as.numeric(acf_abs$acf)[-1])\n\ndf_pacf_abs <- data.frame(\n  lag = as.numeric(pacf_abs$lag),\n  pacf = as.numeric(pacf_abs$acf))\n\nfig_acf_abs <- plot_ly(df_acf_abs, x = ~lag, y = ~acf, type = 'bar', name = 'ACF',\n  marker = list(color = '#1f77b4')) %>%\n  \n  add_segments(x = min(df_acf_abs$lag), xend = max(df_acf_abs$lag), y = ci, yend = ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %>%\n  \n  add_segments(x = min(df_acf_abs$lag), xend = max(df_acf_abs$lag), y = -ci, yend = -ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %>%\n  \n  layout(yaxis = list(title = \"ACF\"))\n\nfig_pacf_abs <- plot_ly(df_pacf_abs, x = ~lag, y = ~pacf, type = 'bar', name = 'PACF',\n  marker = list(color = '#ff7f0e')) %>%\n  \n  add_segments(x = min(df_pacf_abs$lag), xend = max(df_pacf_abs$lag), y = ci, yend = ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %>%\n  \n  add_segments(x = min(df_pacf_abs$lag), xend = max(df_pacf_abs$lag), y = -ci, yend = -ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %>%\n  \n  layout(yaxis = list(title = \"PACF\"))\n\nsubplot(fig_acf_abs, fig_pacf_abs, nrows = 1, margin = 0.05, titleY = TRUE) %>%\n  layout(title = \"Absolute Returns: Autocorrelation & Partial Autocorrelation\",\n  margin = list(t = 50))\n```\n\n::: {.cell-output-display}\n![Absolute Returns ACF and PACF](03-volatility-analysis_files/figure-pdf/acf-pacf-absolute-1.pdf){fig-pos='H' width=100%}\n:::\n:::\n\n\n:::\n\n1. **Volatility Clustering:** The time series plots of both Squared Log-Returns and Absolute Log-Returns clearly illustrate the phenomenon of volatility clustering. We observe distinct periods of high volatility (large spikes) followed by periods of relative calm. This intermittent bursting behavior violates the assumption of constant variance (homoskedasticity) required by standard linear models.\n\n2. **Persistence (Long Memory):** The analysis of the correlograms provides further evidence. Unlike the ACF of raw returns, the ACF of Squared Returns displays significant positive autocorrelation that decays very slowly. A similar, perhaps even clearer, pattern of slow decay is visible in the ACF of Absolute Returns. This \"long memory\" indicates that the magnitude of today's shock has a strong predictive power for future volatility, justifying the use of GARCH-type models.\n\n## Formal Testing for ARCH Effects and Asymmetry\nWhile the graphical analysis provides strong intuitive evidence of conditional heteroskedasticity, we must validate these observations using rigorous statistical procedures. Furthermore, visual inspection alone cannot quantify whether the volatility reacts symmetrically to news or if there is a \"leverage effect\" (where negative returns increase volatility more than positive ones).\n\nTo address this, we perform the following battery of diagnostic tests:\n\n1. **ARCH-LM Test:** To formally test the null hypothesis of no ARCH effects in the residuals up to a specified lag.\n2. **Asymmetry Tests:** useful for checking the presence of asymmetric volatility (leverage effects)\n\n::: {.panel-tabset}\n\n### ARCH Effects\n\n::: {.cell}\n\n```{.r .cell-code}\narma_fit <- Arima(log_returns$LogReturns, order = c(1,0,1))\nresiduals_arma <- residuals(arma_fit)\n\nlags_to_test <- c(5, 10, 20)\n\nrun_arch_lm <- function(lag_val) {  \n  lm_test <- ArchTest(residuals_arma, lags = lag_val)\n  \n  return(data.frame(\n    Lag = lag_val,\n    Statistic = lm_test$statistic,\n    P_Value = lm_test$p.value\n  ))\n}\n\narch_results <- do.call(rbind, lapply(lags_to_test, run_arch_lm))\n\narch_display <- arch_results %>%\n  mutate(\n    Conclusion = ifelse(P_Value < 0.05, \"Reject H0\", \"Fail to Reject\"),\n    P_Value = format.pval(P_Value, digits = 3, eps = 0.001)\n  )\n\nknitr::kable(arch_display,\n  caption = \"Engle's ARCH-LM Test for Volatility Clustering\",\n  align = \"c\", row.names = FALSE)\n```\n\n::: {.cell-output-display}\n\n\nTable: Engle's ARCH-LM Test for Volatility Clustering\n\n| Lag | Statistic | P_Value | Conclusion |\n|:---:|:---------:|:-------:|:----------:|\n|  5  | 870.6739  | <0.001  | Reject H0  |\n| 10  | 983.5282  | <0.001  | Reject H0  |\n| 20  | 1086.0644 | <0.001  | Reject H0  |\n\n\n:::\n:::\n\n\n### Leverage Effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspec_std <- ugarchspec(\n  variance.model = list(model = \"sGARCH\", garchOrder = c(1, 1)),\n  mean.model = list(armaOrder = c(1, 1), include.mean = TRUE),\n  distribution.model = \"std\"\n)\n\nfit_std <- ugarchfit(spec = spec_std, data = log_returns$LogReturns)\nengle_test <- signbias(fit_std)\n\nengle_df <- data.frame(\n  Test = rownames(engle_test),\n  t_value = engle_test[, 1],\n  Prob = engle_test[, 2],\n  Result = ifelse(engle_test[, 2] < 0.05, \"Asymmetry\", \"Symmetry\")\n)\n\nengle_df$Prob <- format.pval(engle_df$Prob, digits = 3, eps = 0.001)\n\nknitr::kable(engle_df, \n  digits = 4, \n  caption = \"Engle-Ng Tests for Asymmetry (Leverage Effect)\",\n  row.names = FALSE,\n  align = \"c\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Engle-Ng Tests for Asymmetry (Leverage Effect)\n\n|        Test        | t_value | Prob  |  Result  |\n|:------------------:|:-------:|:-----:|:--------:|\n|     Sign Bias      | 0.6572  | 0.511 | Symmetry |\n| Negative Sign Bias | 0.3227  | 0.747 | Symmetry |\n| Positive Sign Bias | 0.1283  | 0.898 | Symmetry |\n|    Joint Effect    | 1.5848  | 0.663 | Symmetry |\n\n\n:::\n:::\n\n\n:::\n\n\nThe preliminary diagnostic phase has already established the presence of significant conditional heteroskedasticity, as the **ARCH-LM test strongly rejected the null hypothesis** of constant variance. However, regarding the nature of this volatility, the results diverge from the standard market behavior. Contrary to the stylized facts of broad equity indices—where the Leverage Effect typically induces higher volatility during market downturns—the **Engle-Ng tests for ASML indicate a symmetric volatility response** ($H_0$ is not rejected). This suggests that for ASML, large positive shocks (rallies) generate volatility levels comparable to negative shocks. This behavior is often observed in high-growth technology stocks, where upside volatility is driven by speculative trading and aggressive repricing during expansion cycles.Despite the statistical lack of significant asymmetry, we will proceed with the estimation of asymmetric models (**GJR-GARCH** and **E-GARCH**) alongside the standard specification. This ensures a comprehensive model comparison based on Information Criteria (AIC/BIC), verifying whether these models might still offer a superior fit due to their flexibility in handling the error distribution.\n\n\n## Models\n\nGiven the evidence of volatility clustering and the potential for non-normal error distributions, we estimate three distinct volatility specifications to identify the model that best describes the data generating process of ASML returns.\n\nWe compare the following models:\n\n1. **Standard GARCH (sGARCH):** Assumes symmetric response to shocks.\n2. **GJR-GARCH:** Allows for asymmetric response (leverage effect) targeting the variance directly.\n3. **Exponential GARCH (E-GARCH):** Models the logarithm of variance, allowing for asymmetry without imposing positivity constraints on coefficients.\n\nTo ensure robustness and account for the \"fat tails\" observed in the preliminary analysis (Jarque-Bera test), all models are estimated using a **Student-t distribution** for the innovation process, coupled with the **ARMA(1,1)** mean equation identified in the previous chapter.\n\nWe rely on **Information Criteria (AIC and BIC)** for model selection, where lower values indicate a better trade-off between goodness-of-fit and model parsimony.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncommon_mean <- list(armaOrder = c(1, 1), include.mean = TRUE)\ncommon_dist <- \"std\" \n\nspec_std <- ugarchspec(\n  variance.model = list(model = \"sGARCH\", garchOrder = c(1, 1)),\n  mean.model = common_mean,\n  distribution.model = common_dist\n)\n\nspec_gjr <- ugarchspec(\n  variance.model = list(model = \"gjrGARCH\", garchOrder = c(1, 1)),\n  mean.model = common_mean,\n  distribution.model = common_dist\n)\n\nspec_egarch <- ugarchspec(\n  variance.model = list(model = \"eGARCH\", garchOrder = c(1, 1)),\n  mean.model = common_mean,\n  distribution.model = common_dist\n)\n\nfit_std    <- ugarchfit(spec_std, data = log_returns$LogReturns, solver = \"hybrid\")\nfit_gjr    <- ugarchfit(spec_gjr, data = log_returns$LogReturns, solver = \"hybrid\")\nfit_egarch <- ugarchfit(spec_egarch, data = log_returns$LogReturns, solver = \"hybrid\")\n\ncriteria_df <- data.frame(\n  Model = c(\"sGARCH(1,1)\", \"GJR-GARCH(1,1)\", \"E-GARCH(1,1)\"),\n  AIC = c(infocriteria(fit_std)[1], infocriteria(fit_gjr)[1], infocriteria(fit_egarch)[1]),\n  BIC = c(infocriteria(fit_std)[2], infocriteria(fit_gjr)[2], infocriteria(fit_egarch)[2])\n)\n\ncriteria_df <- criteria_df[order(criteria_df$BIC), ]\n\nknitr::kable(criteria_df, \n  digits = 4, \n  caption = \"Model Selection: AIC and BIC Comparison\",\n  row.names = FALSE,\n  align = \"c\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Model Selection: AIC and BIC Comparison\n\n|     Model      |   AIC   |   BIC   |\n|:--------------:|:-------:|:-------:|\n|  E-GARCH(1,1)  | -4.6872 | -4.6789 |\n| GJR-GARCH(1,1) | -4.6820 | -4.6737 |\n|  sGARCH(1,1)   | -4.6718 | -4.6645 |\n\n\n\nComparison between Symmetric and Asymmetric GARCH\n:::\n:::\n\n\n## Forecast\nSince the information criteria (AIC and BIC) provide an in-sample assessment, we proceed with an Out-of-Sample validation to test the actual predictive capacity on data not used for estimation.\n\nWe split the time series into two subsets:\n\n* **Training Set ($80\\%$)**: Used to estimate the GARCH parameters.\n* **Test Set ($20\\%$)**: Used to compare volatility forecasts against the proxy of realized volatility.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_total <- nrow(log_returns)\nn_train <- floor(0.80 * n_total)\nn_test  <- n_total - n_train\n\ncommon_mean <- list(armaOrder = c(1, 1), include.mean = TRUE)\ncommon_dist <- \"std\"\n\nspec_std <- ugarchspec(\n  variance.model = list(model = \"sGARCH\", garchOrder = c(1, 1)), \n  mean.model = common_mean, distribution.model = common_dist)\n\nspec_gjr <- ugarchspec(\n  variance.model = list(model = \"gjrGARCH\", garchOrder = c(1, 1)), \n  mean.model = common_mean, distribution.model = common_dist)\n\nspec_egarch <- ugarchspec(\n  variance.model = list(model = \"eGARCH\", garchOrder = c(1, 1)), \n  mean.model = common_mean, distribution.model = common_dist)\n\nroll_std <- ugarchroll(\n  spec_std, data = log_returns$LogReturns, n.ahead = 1, \n  n.start = n_train, refit.every = 50, refit.window = \"moving\", solver = \"hybrid\")\n\nroll_gjr <- ugarchroll(\n  spec_gjr, data = log_returns$LogReturns, n.ahead = 1, \n  n.start = n_train, refit.every = 50, refit.window = \"moving\", solver = \"hybrid\")\n\nroll_egarch <- ugarchroll(\n  spec_egarch, data = log_returns$LogReturns, n.ahead = 1, \n  n.start = n_train, refit.every = 50, refit.window = \"moving\", solver = \"hybrid\")\n```\n:::\n\n\nThe following plot displays the estimated conditional volatility $(\\hat{\\sigma}_t)$ generated by the sGARCH, GJR-GARCH and E-GARCH model:\n\n::: {.callout-note}\nUnlike price forecasting, volatility is **latent** (not directly observable). Therefore, in the following chart, we visually compare the forecasted standard deviation $\\hat{\\sigma}_t$ (colored lines) against the **Absolute Returns** $|r_t|$ (grey bars). While noisy, absolute returns serve as a standard unbiased proxy for actual market turbulence.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_plot <- as.data.frame(roll_egarch)\n\ndf_plot$Date <- log_returns$Date[(n_train + 1):n_total]\ndf_plot$AbsReturn <- abs(df_plot$Realized)\ndf_plot$Sigma_EGARCH <- df_plot$Sigma\ndf_plot$Sigma_GJR <- as.data.frame(roll_gjr)$Sigma\ndf_plot$Sigma_STD <- as.data.frame(roll_std)$Sigma\n\nfig_unified <- plot_ly(data = df_plot, x = ~Date) %>%\n  \n  add_bars(y = ~AbsReturn, name = 'Abs Returns (|r|)', \n  marker = list(color = 'lightgrey'), opacity = 0.5) %>%\n  \n  add_lines(y = ~Sigma_STD, name = 'sGARCH',\n  line = list(color = 'green', width = 1.5)) %>%\n  \n  add_lines(y = ~Sigma_GJR, name = 'GJR-GARCH',\n  line = list(color = 'steelblue', width = 1.5)) %>%\n  \n  add_lines(y = ~Sigma_EGARCH, name = 'E-GARCH',\n  line = list(color = 'darkorange', width = 1.5)) %>%\n  \n  layout(\n    title = \"Volatility Forecast Comparison (Refit Window: 50 Days)\",\n    yaxis = list(title = \"Volatility (Sigma)\"),\n    xaxis = list(title = \"Date\"),\n    legend = list(orientation = \"h\", x = 0.1, y = -0.2),\n    barmode = \"overlay\",\n    hovermode = \"x unified\"\n  )\n\nfig_unified\n```\n\n::: {.cell-output-display}\n![Volatility Forecast Comparison: sGARCH vs GJR-GARCH vs E-GARCH](03-volatility-analysis_files/figure-pdf/plot-vol-unified-1.pdf){fig-pos='H' width=100%}\n:::\n:::\n\n\n\nWe evaluate the predictive performance using two loss functions, utilizing squared returns $(r_t^2)$ as the proxy for latent variance:\n\n* **RMSE (Root Mean Squared Error):** Standard symmetric metric.\n* **QLIKE (Quasi-Likelihood):** Asymmetric loss function that penalizes under-prediction of risk more heavily. **This is the preferred metric for volatility model selection.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncalc_vol_metrics <- function(roll_obj, name) {\n  df <- as.data.frame(roll_obj)\n  actual_var <- df$Realized^2\n  pred_var   <- df$Sigma^2\n  \n  rmse <- sqrt(mean((actual_var - pred_var)^2))\n  qlike <- mean(log(pred_var) + (actual_var / pred_var))\n  \n  return(c(Model = name, RMSE = rmse, QLIKE = qlike))\n}\n\nm_std <- calc_vol_metrics(roll_std, \"sGARCH(1,1)\")\nm_gjr <- calc_vol_metrics(roll_gjr, \"GJR-GARCH(1,1)\")\nm_eg <- calc_vol_metrics(roll_egarch, \"E-GARCH(1,1)\")\n\nvol_val_table <- data.frame(rbind(m_std, m_gjr, m_eg))\nvol_val_table$RMSE <- as.numeric(vol_val_table$RMSE)\nvol_val_table$QLIKE <- as.numeric(vol_val_table$QLIKE)\nvol_val_table <- vol_val_table[order(vol_val_table$QLIKE), ]\n\ndatatable(vol_val_table, options = list(dom = 't'), rownames = FALSE) %>%\n  formatRound(columns = c('RMSE', 'QLIKE'), digits = 5)\n```\n\n::: {.cell-output-display}\n![](03-volatility-analysis_files/figure-pdf/vol-forecast-validation-1.pdf){fig-pos='H' width=100%}\n:::\n:::\n\n\n## Conclusion\n\nThe comprehensive analysis conducted in this chapter—spanning diagnostic tests, in-sample information criteria, and out-of-sample forecasting—provides a clear and robust picture of ASML's risk profile.\n\nThe results confirm the standard stylized facts of financial time series regarding the presence of **volatility clustering**: the rejection of the null hypothesis in the **ARCH-LM test** proves that ASML's volatility is not constant but evolves dynamically over time.\n\nHowever, a distinct and insightful characteristic emerged regarding the *nature* of this volatility. Contrary to broad equity indices—where the \"Leverage Effect\" typically induces higher volatility during market downturns—our analysis highlights an **unusually low leverage effect**. This is supported by multiple converging evidences:\n\n1.  The **Engle-Ng diagnostic tests**, which failed to reject the hypothesis of symmetry.\n2.  The **Quantitative Performance Metrics**, where both in-sample Information Criteria (AIC/BIC) and Out-of-Sample forecast error measures (RMSE/QLIKE) **do not exhibit significant distinctions** across specifications. The complex asymmetric models (GJR and E-GARCH) failed to provide a substantial improvement over the standard benchmark, implying that the asymmetry component adds little explanatory power.\n\nThis symmetric behavior, while atypical for the general market, is characteristic of **high-growth technology stocks**. For ASML, large positive shocks (rallies) generate volatility levels comparable to negative shocks (crashes), likely driven by speculative trading and aggressive repricing during expansion cycles.\n\n**Final Model Selection:**\nGiven the negligible difference in performance metrics, we invoke the **Principle of Parsimony**  and select the **sGARCH(1,1) with Student-t distribution** as the optimal model. It offers the simplest and most robust representation of the data generating process, correctly capturing the fat tails and volatility clustering without overfitting a leverage effect that is not structurally significant.\n\nWe conclude this analysis by visually translating the statistical estimates of the selected model into a practical Risk Management metric. The following chart displays the **Dynamic Value at Risk (VaR)**, showing the estimated thresholds for the maximum expected loss at 95% and 99% confidence levels.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsigma_t <- sigma(fit_std)\nmu_t    <- fitted(fit_std)\nshape_param <- coef(fit_std)[\"shape\"]\n\nq_05 <- qdist(distribution = \"std\", p = 0.05, shape = shape_param)\nq_01 <- qdist(distribution = \"std\", p = 0.01, shape = shape_param)\n\nVaR_95 <- mu_t + sigma_t * q_05\nVaR_99 <- mu_t + sigma_t * q_01\n\ndf_risk <- data.frame(\n  Date = log_returns$Date,\n  Returns = log_returns$LogReturns,\n  VaR_95 = as.numeric(VaR_95),\n  VaR_99 = as.numeric(VaR_99)\n)\n\nfig_var <- plot_ly(df_risk, x = ~Date)\n\nfig_var <- add_trace(\n  fig_var, y = ~Returns, type = 'scatter', mode = 'lines',\n  name = 'Log Returns', line = list(color = 'grey', width = 0.5, opacity = 0.5)\n)\n\nfig_var <- add_trace(\n  fig_var, y = ~VaR_95, type = 'scatter', mode = 'lines',\n  name = 'VaR 95% (sGARCH)', line = list(color = 'orange', width = 1.5)\n)\n\nfig_var <- add_trace(\n  fig_var, y = ~VaR_99, type = 'scatter', mode = 'lines',\n  name = 'VaR 99% (sGARCH)', line = list(color = 'darkred', width = 1.5)\n)\n\nfig_var <- layout(\n  fig_var,\n  title = \"Risk Management: ASML Returns vs Dynamic VaR (sGARCH)\",\n  yaxis = list(title = \"Log Return\"),\n  xaxis = list(title = \"Date\"),\n  legend = list(orientation = \"h\", x = 0.1, y = -0.2)\n)\n\nfig_var\n```\n\n::: {.cell-output-display}\n![Value at Risk (VaR) In-Sample with sGARCH(1,1)](03-volatility-analysis_files/figure-pdf/var-calculation-1.pdf){fig-pos='H' width=100%}\n:::\n:::\n\n",
    "supporting": [
      "03-volatility-analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}