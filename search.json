[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ASML Stock Price Analysis",
    "section": "",
    "text": "Preface\nThis project aims to conduct an in-depth time series analysis of the stock prices for ASML Holding NV (ASML), a global leader in the manufacturing of lithography systems for the semiconductor industry. The primary objective is to explore the dynamics of historical prices, volatility, and underlying trends of the stock.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#data-source",
    "href": "index.html#data-source",
    "title": "ASML Stock Price Analysis",
    "section": "Data Source",
    "text": "Data Source\nWe retrieve historical daily data using the quantmod R package, focusing on the Adjusted Closing Price to account for dividends and stock splits.\n\nTicker: ASML\nSource: Yahoo Finance\nStart Date: 2000-01-01\nEnd Date: 2025-12-31",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#data-loading",
    "href": "index.html#data-loading",
    "title": "ASML Stock Price Analysis",
    "section": "Data Loading",
    "text": "Data Loading\nThe dataset structure is shown below:\n\n\nCode\ndatatable(\n  tail(asml, 100),\n  rownames = FALSE,\n  options = list(\n    pageLength = 10,\n    order = list(list(0, 'desc'))\n  )\n)",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "qmd/01-EDA.html",
    "href": "qmd/01-EDA.html",
    "title": "1  Exploratory Data Analysis",
    "section": "",
    "text": "1.1 Adjusted closing prices\nLet us plot the adjusted closing prices…\nCode\nfig_asml &lt;- plot_ly(data = asml, x = ~Date, y = ~ASML.Adjusted, \n  type = 'scatter', mode = 'lines', name = 'ASML Adjusted',\n  line = list(color = 'darkblue', width = 1.5))\n\nfig_asml &lt;- layout(\n  fig_asml,\n  title = \"ASML Stock Price Evolution\",\n  xaxis = list(\n    title = \"Date\",\n    rangeslider = list(visible = TRUE),\n    rangeselector = list(\n      buttons = list(\n        list(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n        list(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n        list(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n        list(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n        list(step=\"all\")\n      )\n    )\n  )\n)\n\nfig_asml\n\n\n\n\nASML Daily Adjusted Closing Prices\nThe graph clearly shows that the price series is non-stationary: the mean is not constant (it exhibits trends), and the variance appears to fluctuate depending on the price level. Consequently, standard statistical inference cannot be directly applied to prices.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploratory Data Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/01-EDA.html#log-returns",
    "href": "qmd/01-EDA.html#log-returns",
    "title": "1  Exploratory Data Analysis",
    "section": "1.2 Log returns",
    "text": "1.2 Log returns\nTo obtain a stationary process, we transform prices into log-returns. Let \\(P_t\\) be the price at time \\(t\\). The simple net return is defined as:\n\\[R_t = \\frac{P_t - P_{t-1}}{P_{t-1}}\\]\nHowever, in financial econometrics, log-returns (\\(r_t\\)) are preferred due to their time-additivity property. The log-return is defined as the natural logarithm of the gross return:\n\\[ r_t = \\ln\\left(\\frac{P_t}{P_{t-1}}\\right) = \\ln(P_t) - \\ln(P_{t-1}) \\]\nWe compute the log-returns for ASML in R:\n\n\nCode\nlog_ret_vec &lt;- diff(log(asml$ASML.Adjusted))\nlog_ret_vec &lt;- log_ret_vec[is.finite(log_ret_vec)]\n\nlog_returns &lt;- data.frame(\n  Date = asml$Date[-1],\n  LogReturns = as.numeric(log_ret_vec)\n)\n\n\nLet’s visualize the log-returns of ASML:\n\n\nCode\nfig_log &lt;- plot_ly(data = log_returns, x = ~Date, y = ~LogReturns, type = 'scatter',\n  mode = 'lines', name = 'Log Returns', line = list(color = 'darkred', width = 1))\n\nfig_log &lt;- layout(\n  fig_log,\n  title = \"ASML Log-Returns\",\n  xaxis = list(title = \"Date\"),\n  yaxis = list(title = \"Log Return\"),\n  shapes = list(\n    list(\n      type = \"line\",\n      x0 = min(log_returns$Date),\n      x1 = max(log_returns$Date),\n      y0 = 0, \n      y1 = 0,\n      line = list(color = \"black\", width = 1)\n    )\n  )\n)\n\nfig_log\n\n\n\n\nASML Daily Log-Returns\n\n\nUnlike prices, the log-returns oscillate around a constant mean (close to zero). This behavior suggests that the return series is stationary, satisfying the conditions for further econometric analysis.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploratory Data Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/01-EDA.html#distribution-analysis",
    "href": "qmd/01-EDA.html#distribution-analysis",
    "title": "1  Exploratory Data Analysis",
    "section": "1.3 Distribution analysis",
    "text": "1.3 Distribution analysis\nWe analyze the distribution of log-returns to check for deviations from normality (e.g., fat tails or asymmetry).\n\n1.3.1 Graphical representation\n\n1.3.1.1 Histogram\nThe graphical representation using a histogram of the frequency distribution of returns observed over a given sample period provides an initial indication of the characteristics of the probability distribution that generated them.\n\n\nCode\nmu_ret &lt;- mean(log_returns$LogReturns)\nsd_ret &lt;- sd(log_returns$LogReturns)\n\nt_fit_fGarch &lt;- stdFit(log_returns$LogReturns * 100)\nt_params &lt;- t_fit_fGarch$par\nt_label &lt;- sprintf(\"Student-t (df=%.2f)\", t_params[\"nu\"])\n\nfig_dist &lt;- plot_ly(data = log_returns, x = ~LogReturns,\n  type = \"histogram\", name = \"Log Returns\", histnorm = \"probability density\",\n  marker = list(color = \"lightgray\", line = list(color = \"gray\", width = 1)),\n  opacity = 0.7)\n\nx_seq &lt;- seq(min(log_returns$LogReturns), max(log_returns$LogReturns), length.out = 500)\n\ny_norm &lt;- dnorm(x_seq, mean = mu_ret, sd = sd_ret)\ny_t &lt;- dstd(\n  x_seq,\n  mean = t_params[\"mean\"]/100,\n  sd = t_params[\"sd\"]/100,\n  nu = t_params[\"nu\"]\n)\n\nfig_dist &lt;- fig_dist %&gt;%\n  add_lines(\n    x = x_seq,\n    y = y_norm,\n    name = \"Normal Distribution\",\n    line = list(color = \"#E74C3C\", width = 2, dash = \"dash\"),\n    inherit = FALSE\n  ) %&gt;% \n  \n  add_lines(\n    x = x_seq,\n    y = y_t,\n    name = t_label,\n    line = list(color = \"#2E86C1\", width = 2),\n    inherit = FALSE\n  ) %&gt;% \n  \n  layout(\n    title = \"Distribution of ASML Log-Returns\",\n    xaxis = list(title = \"Log Return\"),\n    yaxis = list(title = \"Density\"),\n    legend = list(x = 0.8, y = 0.9),\n    hovermode = \"x unified\"\n  )\n\nfig_dist\n\n\n\n\nHistogram of ASML Log-Returns\n\n\nThe histogram indicates that the distribution of log-returns is closer to a Student-t distribution than to a Normal distribution.\n\n\n1.3.1.2 Q-Q plot\n\n\nCode\nvec_ret &lt;- log_returns$LogReturns\n\nqq_vals &lt;- qqnorm(vec_ret, plot.it = FALSE)\nqq_data &lt;- data.frame(\n  Theoretical = qq_vals$x,\n  Sample = qq_vals$y\n)\n\ny &lt;- quantile(vec_ret, c(0.25, 0.75), names = FALSE)\nx &lt;- qnorm(c(0.25, 0.75))\nslope &lt;- diff(y)/diff(x)\nint &lt;- y[1L] - slope * x[1L]\n\nfig_qq &lt;- plot_ly(data = qq_data, x = ~Theoretical, y = ~Sample, type = 'scatter',\n  mode = 'markers', marker = list(size = 3, color = '#2E86C1', opacity = 0.6),\n  name = \"Returns\")\n\nfig_qq &lt;- fig_qq %&gt;%\n  add_lines(\n    x = ~Theoretical,\n    y = ~Theoretical * slope + int, \n    line = list(color = \"#E74C3C\", width = 2, dash = \"dash\"), \n    name = \"Normal Reference\",\n    inherit = FALSE\n    ) %&gt;%\n    \n    layout(\n      title = \"Q-Q Plot: Normal vs Empirical\",\n      xaxis = list(title = \"Theoretical Quantiles (Normal)\"),\n      yaxis = list(title = \"Sample Quantiles (ASML)\")\n    )\n\nfig_qq\n\n\n\n\nQ-Q Plot of ASML Log-Returns\n\n\nThe Q-Q plot confirms the findings from the histogram. While the central observations (the body of the distribution) align well with the theoretical normal line (in red), the extreme values at both ends deviate significantly, forming an ‘S-shape’. This provides clear visual evidence of fat tails (leptokurtosis), reinforcing the stylized fact that extreme market movements occur more frequently than predicted by a Gaussian model.\n\n\n\n1.3.2 Synthetic indicators\n\n\nCode\ndesc_stats &lt;- data.frame(\n  Metric = c(\"Mean\", \"Std. Dev.\", \"Skewness\", \"Kurtosis\"),\n  Value = c(\n    mean(log_returns$LogReturns),\n    sd(log_returns$LogReturns),\n    skewness(log_returns$LogReturns),\n    kurtosis(log_returns$LogReturns)\n  )\n)\n\ndatatable(\n  desc_stats, \n  options = list(dom = 't', paging = FALSE), \n  rownames = FALSE\n  ) %&gt;% formatRound('Value', digits = 5)\n\n\n\n\n\n\nAs we can see, the distribution has a mean close to zero, slight negative skewness, and significant leptokurtosis (fat tails). These characteristics align with the well-known stylized facts of financial log-returns, indicating a departure from normality.\n\n\n1.3.3 Test of normality\nTo formally test the normality hypothesis, we employ the Jarque-Bera test, which is based on skewness and kurtosis matching a normal distribution.\n\\[ H_0: \\text{The data is normally distributed (Skewness=0, Kurtosis=3)} \\] \\[ H_1: \\text{The data is not normally distributed} \\]\n\n\nCode\njb_test &lt;- jarque.bera.test(log_returns$LogReturns)\n\njb_res &lt;- data.frame(\n  Test = \"Jarque-Bera\",\n  Statistic = round(jb_test$statistic, 2),\n  P_Value = ifelse(jb_test$p.value &lt; 0.001, \"&lt; 0.001\", round(jb_test$p.value, 4)),\n  Result = ifelse(jb_test$p.value &lt; 0.05, \"Reject H0\", \"Fail to Reject H0\")\n)\ndatatable(jb_res, options = list(dom = 't'), rownames = FALSE)\n\n\n\n\n\n\nSince the p-value is virtually zero (&lt;0.001), we strongly reject the null hypothesis of normality. This confirms that ASML returns are not normally distributed.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploratory Data Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/02-return-analysis.html",
    "href": "qmd/02-return-analysis.html",
    "title": "2  Return Analysis",
    "section": "",
    "text": "2.1 ACF and PACF Analysis\nThe objective of this chapter is to identify the optimal ARMA(p,q) model to describe the dynamics of ASML log-returns. To determine the most suitable stochastic process, we adopt a systematic approach structured in the following stages:\nAnalyzing correlograms is the preliminary step to identify potential orders for the AR (AutoRegressive) and MA (Moving Average) components.\nCode\nacf_res &lt;- acf(log_returns$LogReturns, plot = FALSE, lag.max = 20)\npacf_res &lt;- pacf(log_returns$LogReturns, plot = FALSE, lag.max = 20)\n\nci &lt;- qnorm((1 + 0.95)/2)/sqrt(length(log_returns$LogReturns))\n\ndf_acf &lt;- data.frame(\n  lag = as.numeric(acf_res$lag)[-1],\n  acf = as.numeric(acf_res$acf)[-1])\n\ndf_pacf &lt;- data.frame(\n  lag = as.numeric(pacf_res$lag),\n  pacf = as.numeric(pacf_res$acf))\n\nfig_acf &lt;- plot_ly(df_acf, x = ~lag, y = ~acf, type = 'bar', name = 'ACF',\n  marker = list(color = '#1f77b4')) %&gt;%\n  \n  add_segments(x = min(df_acf$lag), xend = max(df_acf$lag), y = ci, yend = ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %&gt;%\n  \n  add_segments(x = min(df_acf$lag), xend = max(df_acf$lag), y = -ci, yend = -ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %&gt;%\n  \n  layout(yaxis = list(title = \"ACF\"))\n\nfig_pacf &lt;- plot_ly(df_pacf, x = ~lag, y = ~pacf, type = 'bar', name = 'PACF',\n  marker = list(color = '#ff7f0e')) %&gt;%\n  \n  add_segments(x = min(df_pacf$lag), xend = max(df_pacf$lag), y = ci, yend = ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %&gt;%\n  \n  add_segments(x = min(df_pacf$lag), xend = max(df_pacf$lag), y = -ci, yend = -ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %&gt;%\n  \n  layout(yaxis = list(title = \"PACF\"))\n\nsubplot(fig_acf, fig_pacf, nrows = 1, margin = 0.05, titleY = TRUE) %&gt;%\n  layout(title = \"Autocorrelation & Partial Autocorrelation\", margin = list(t = 50))\n\n\n\n\nLog-Returns ACF and PACF\nObservations: The autocorrelation at lag-1 is statistically significant, yet its magnitude is limited (approximately -0.04). Neither the ACF nor the PACF exhibits a clear decay or a sharp cutoff. This ambiguity makes it difficult to visually identify a pure AR or MA process, suggesting instead a mixed ARMA structure.\nA classical iterative approach (“Box-Jenkins”) would proceed by analyzing the residuals:\nHowever, given the ambiguity of the observed patterns and considering that high-order lags (\\(&gt;3\\)) are uncommon in financial contexts, we opted for a more transparent and systematic approach. We will perform a comprehensive search, testing all possible combinations within a limited range.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Return Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/02-return-analysis.html#acf-and-pacf-analysis",
    "href": "qmd/02-return-analysis.html#acf-and-pacf-analysis",
    "title": "2  Return Analysis",
    "section": "",
    "text": "If the residuals’ ACF shows a sharp cutoff \\(\\rightarrow\\) add an MA term.\nIf the residuals’ PACF shows a sharp cutoff \\(\\rightarrow\\) add an AR term.\nIf both plots decay slowly or are unclear \\(\\rightarrow\\) increase both orders.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Return Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/02-return-analysis.html#models",
    "href": "qmd/02-return-analysis.html#models",
    "title": "2  Return Analysis",
    "section": "2.2 Models",
    "text": "2.2 Models\nTo assess the goodness of fit for each configuration, we analyze two fundamental diagnostic outputs:\n\nResidual Analysis (checkresiduals): This function allows us to verify the absence of autocorrelation in the residuals. In addition to a visual inspection of the plots, the Ljung-Box Test is performed.\n\n\\(H_0\\) (Null Hypothesis): The residuals are independently distributed (White Noise).\nInterpretation: A p-value \\(&gt;0.05\\) indicates that there is insufficient evidence to reject the null hypothesis. Therefore, the model has adequately captured the temporal structure of the data.\n\nParameter Significance (coeftest): This reports the estimated coefficients (ar and ma) along with their Standard Errors. Using the z-test, we verify whether the coefficients are statistically different from zero (p-value \\(&lt;0.05\\)).\n\n\n\nCode\nset.seed(123)\n\n\n\nAR(1)MA(1)ARMA(1,1)AR(2)MA(2)ARMA(1,2)ARMA(2,1)ARMA(2,2)AR(3)MA(3)ARMA(1,3)ARMA(2,3)ARMA(3,1)ARMA(3,2)ARMA(3,3)\n\n\n\n\nCode\narma_10 &lt;- Arima(log_returns$LogReturns, order=c(1,0,0))\ncheckresiduals(arma_10)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,0,0) with non-zero mean\nQ* = 39.515, df = 9, p-value = 9.299e-06\n\nModel df: 1.   Total lags used: 10\n\n\nCode\ncoeftest(arma_10)\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value Pr(&gt;|z|)   \nar1       -0.03766328  0.01236477 -3.0460 0.002319 **\nintercept  0.00051722  0.00033887  1.5263 0.126937   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_01 &lt;- Arima(log_returns$LogReturns, order=c(0,0,1))\ncheckresiduals(arma_01)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,1) with non-zero mean\nQ* = 39.316, df = 9, p-value = 1.01e-05\n\nModel df: 1.   Total lags used: 10\n\n\nCode\ncoeftest(arma_01)\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value Pr(&gt;|z|)   \nma1       -0.03870356  0.01255525 -3.0827 0.002052 **\nintercept  0.00051675  0.00033802  1.5288 0.126326   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_11 &lt;- Arima(log_returns$LogReturns, order=c(1,0,1))\ncheckresiduals(arma_11)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,0,1) with non-zero mean\nQ* = 30.019, df = 8, p-value = 0.0002097\n\nModel df: 2.   Total lags used: 10\n\n\nCode\ncoeftest(arma_11)\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value  Pr(&gt;|z|)    \nar1        0.74803078  0.09296953  8.0460 8.556e-16 ***\nma1       -0.78463504  0.08698476 -9.0204 &lt; 2.2e-16 ***\nintercept  0.00049195  0.00030041  1.6376    0.1015    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_20 &lt;- Arima(log_returns$LogReturns, order=c(2,0,0))\ncheckresiduals(arma_20)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,0,0) with non-zero mean\nQ* = 39.327, df = 8, p-value = 4.275e-06\n\nModel df: 2.   Total lags used: 10\n\n\nCode\ncoeftest(arma_20)\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value Pr(&gt;|z|)   \nar1       -0.03811219  0.01237289 -3.0803 0.002068 **\nar2       -0.01178765  0.01237261 -0.9527 0.340731   \nintercept  0.00051767  0.00033491  1.5457 0.122176   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_02 &lt;- Arima(log_returns$LogReturns, order=c(0,0,2))\ncheckresiduals(arma_02)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,2) with non-zero mean\nQ* = 38.929, df = 8, p-value = 5.066e-06\n\nModel df: 2.   Total lags used: 10\n\n\nCode\ncoeftest(arma_02)\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value Pr(&gt;|z|)   \nma1       -0.03931359  0.01239570 -3.1716 0.001516 **\nma2       -0.01363511  0.01243057 -1.0969 0.272685   \nintercept  0.00051676  0.00033299  1.5519 0.120694   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_12 &lt;- Arima(log_returns$LogReturns, order=c(1,0,2))\ncheckresiduals(arma_12)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,0,2) with non-zero mean\nQ* = 29.667, df = 7, p-value = 0.0001093\n\nModel df: 3.   Total lags used: 10\n\n\nCode\ncoeftest(arma_12)\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value  Pr(&gt;|z|)    \nar1        0.74660442  0.12291149  6.0743 1.245e-09 ***\nma1       -0.78624421  0.12342306 -6.3703 1.886e-10 ***\nma2        0.00387487  0.01562497  0.2480    0.8041    \nintercept  0.00052359  0.00030184  1.7346    0.0828 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_21 &lt;- Arima(log_returns$LogReturns, order=c(2,0,1))\ncheckresiduals(arma_21)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,0,1) with non-zero mean\nQ* = 29.433, df = 7, p-value = 0.0001206\n\nModel df: 3.   Total lags used: 10\n\n\nCode\ncoeftest(arma_21)\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value  Pr(&gt;|z|)    \nar1        0.75216134  0.10514098  7.1538 8.439e-13 ***\nar2        0.00505353  0.01520891  0.3323   0.73968    \nma1       -0.79218013  0.10452116 -7.5791 3.479e-14 ***\nintercept  0.00052281  0.00030083  1.7379   0.08223 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_22 &lt;- Arima(log_returns$LogReturns, order=c(2,0,2))\ncheckresiduals(arma_22)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,0,2) with non-zero mean\nQ* = 27.067, df = 6, p-value = 0.0001407\n\nModel df: 4.   Total lags used: 10\n\n\nCode\ncoeftest(arma_22)\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value  Pr(&gt;|z|)    \nar1        0.13889774  0.20808368  0.6675 0.5044470    \nar2        0.49269101  0.13447436  3.6638 0.0002485 ***\nma1       -0.18349571  0.20966818 -0.8752 0.3814804    \nma2       -0.50222839  0.14273213 -3.5187 0.0004337 ***\nintercept  0.00052958  0.00029978  1.7666 0.0772978 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_30 &lt;- Arima(log_returns$LogReturns, order=c(3,0,0))\ncheckresiduals(arma_30)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(3,0,0) with non-zero mean\nQ* = 27.506, df = 7, p-value = 0.0002702\n\nModel df: 3.   Total lags used: 10\n\n\nCode\ncoeftest(arma_30)\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value  Pr(&gt;|z|)    \nar1       -0.03863782  0.01236319 -3.1252 0.0017767 ** \nar2       -0.01340434  0.01237126 -1.0835 0.2785840    \nar3       -0.04157144  0.01236735 -3.3614 0.0007755 ***\nintercept  0.00051836  0.00032127  1.6135 0.1066419    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_03 &lt;- Arima(log_returns$LogReturns, order=c(0,0,3))\ncheckresiduals(arma_03)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,3) with non-zero mean\nQ* = 26.596, df = 7, p-value = 0.000394\n\nModel df: 3.   Total lags used: 10\n\n\nCode\ncoeftest(arma_03)\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value  Pr(&gt;|z|)    \nma1       -0.03884123  0.01237078 -3.1398 0.0016909 ** \nma2       -0.01337127  0.01235618 -1.0822 0.2791849    \nma3       -0.04358374  0.01269756 -3.4325 0.0005982 ***\nintercept  0.00051686  0.00031767  1.6270 0.1037265    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_13 &lt;- Arima(log_returns$LogReturns, order=c(1,0,3))\ncheckresiduals(arma_13)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,0,3) with non-zero mean\nQ* = 27.07, df = 6, p-value = 0.0001405\n\nModel df: 4.   Total lags used: 10\n\n\nCode\ncoeftest(arma_13)\n\n\nWarning in sqrt(diag(se)): NaNs produced\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value Pr(&gt;|z|)  \nar1        0.33895106         NaN     NaN      NaN  \nma1       -0.37787376         NaN     NaN      NaN  \nma2       -0.00033557         NaN     NaN      NaN  \nma3       -0.03535024         NaN     NaN      NaN  \nintercept  0.00051530  0.00031168  1.6533  0.09828 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_23 &lt;- Arima(log_returns$LogReturns, order=c(2,0,3))\ncheckresiduals(arma_23)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,0,3) with non-zero mean\nQ* = 25.221, df = 5, p-value = 0.0001263\n\nModel df: 5.   Total lags used: 10\n\n\nCode\ncoeftest(arma_23)\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value Pr(&gt;|z|)  \nar1        0.12928859  0.26476852  0.4883  0.62533  \nar2        0.22589080  0.19486455  1.1592  0.24637  \nma1       -0.16826815  0.26487623 -0.6353  0.52525  \nma2       -0.23309281  0.19068257 -1.2224  0.22155  \nma3       -0.03297002  0.01859016 -1.7735  0.07614 .\nintercept  0.00050770  0.00030819  1.6474  0.09948 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_31 &lt;- Arima(log_returns$LogReturns, order=c(3,0,1))\ncheckresiduals(arma_31)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(3,0,1) with non-zero mean\nQ* = 27.5, df = 6, p-value = 0.0001167\n\nModel df: 4.   Total lags used: 10\n\n\nCode\ncoeftest(arma_31)\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value Pr(&gt;|z|)   \nar1       -0.01946408  0.55210686 -0.0353 0.971877   \nar2       -0.01274576  0.02435614 -0.5233 0.600760   \nar3       -0.04139634  0.01342376 -3.0838 0.002044 **\nma1       -0.01920247  0.55288877 -0.0347 0.972294   \nintercept  0.00051900  0.00032097  1.6170 0.105887   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_32 &lt;- Arima(log_returns$LogReturns, order=c(3,0,2))\ncheckresiduals(arma_32)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(3,0,2) with non-zero mean\nQ* = 40.334, df = 5, p-value = 1.279e-07\n\nModel df: 5.   Total lags used: 10\n\n\nCode\ncoeftest(arma_32)\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error  z value  Pr(&gt;|z|)    \nar1        0.03147753  0.02132298   1.4762  0.139883    \nar2       -0.97055711  0.01697418 -57.1784 &lt; 2.2e-16 ***\nar3       -0.03525799  0.01280948  -2.7525  0.005914 ** \nma1       -0.06976751  0.01731179  -4.0301 5.576e-05 ***\nma2        0.96109526  0.02058307  46.6935 &lt; 2.2e-16 ***\nintercept  0.00053285  0.00033637   1.5841  0.113169    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nCode\narma_33 &lt;- Arima(log_returns$LogReturns, order=c(3,0,3))\ncheckresiduals(arma_33)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(3,0,3) with non-zero mean\nQ* = 8.5727, df = 4, p-value = 0.07271\n\nModel df: 6.   Total lags used: 10\n\n\nCode\ncoeftest(arma_33)\n\n\nWarning in sqrt(diag(se)): NaNs produced\n\n\n\nz test of coefficients:\n\n             Estimate  Std. Error  z value Pr(&gt;|z|)    \nar1       -0.93303265         NaN      NaN      NaN    \nar2        0.68686580  0.06141265  11.1844  &lt; 2e-16 ***\nar3        0.81111732  0.07456554  10.8779  &lt; 2e-16 ***\nma1        0.89063594         NaN      NaN      NaN    \nma2       -0.72881204  0.05908310 -12.3354  &lt; 2e-16 ***\nma3       -0.80508569  0.07150341 -11.2594  &lt; 2e-16 ***\nintercept  0.00060076  0.00028783   2.0872  0.03687 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nAs observed from the outputs, the simpler models (such as AR(1) and MA(1)) yield very low p-values for the Ljung-Box test (\\(&lt;0.05\\)). This indicates that significant autocorrelation remains within the residuals, implying that these models have failed to capture all the relevant information.\nConversely, as we increase complexity towards an ARMA(3,3), the p-value rises above the critical 5% threshold. Consequently, we fail to reject the null hypothesis: the residuals of this model behave as White Noise. This suggests that the ARMA(3,3) is mathematically effective in capturing the patterns of the time series, although its high complexity warrants caution regarding the risk of overfitting.\nAdditionally, the ARMA(1,3) model exhibits instability in parameter estimation (incalculable Std. Error), pointing to potential over-parameterization.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Return Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/02-return-analysis.html#aic-vs-bic",
    "href": "qmd/02-return-analysis.html#aic-vs-bic",
    "title": "2  Return Analysis",
    "section": "2.3 AIC vs BIC",
    "text": "2.3 AIC vs BIC\nWe visualize the trends of the information criteria for all estimated models.\n\n\nCode\nmodels_list &lt;- list(\n  \"AR(1)\" = arma_10, \"MA(1)\" = arma_01, \"ARMA(1,1)\" = arma_11,\n  \"AR(2)\" = arma_20, \"MA(2)\" = arma_02, \"ARMA(1,2)\" = arma_12,\n  \"ARMA(2,1)\" = arma_21, \"ARMA(2,2)\" = arma_22,\n  \"AR(3)\" = arma_30, \"MA(3)\" = arma_03, \"ARMA(1,3)\" = arma_13,\n  \"ARMA(2,3)\" = arma_23, \"ARMA(3,1)\" = arma_31, \"ARMA(3,2)\" = arma_32,\n  \"ARMA(3,3)\" = arma_33\n)\n\nmetrics_df &lt;- data.frame(\n  Model = names(models_list),\n  AIC = sapply(models_list, AIC),\n  BIC = sapply(models_list, BIC)\n)\n\nmetrics_df$Model &lt;- factor(metrics_df$Model, levels = metrics_df$Model)\n\nmin_aic_val &lt;- min(metrics_df$AIC)\nmin_bic_val &lt;- min(metrics_df$BIC)\n\nplot_aic &lt;- plot_ly(metrics_df, x = ~Model, y = ~AIC, name = 'AIC',\n  type = 'scatter', mode = 'lines+markers',\n  line = list(color = '#1f77b4', width = 2),\n  marker = list(size = 8, color = '#1f77b4')) %&gt;% \n  layout(title = \"AIC Trend\", yaxis = list(title = \"AIC\"))\n\nbest_aic &lt;- metrics_df[metrics_df$AIC == min_aic_val, ]\nplot_aic &lt;- plot_aic %&gt;%\n  add_trace(data = best_aic, x = ~Model, y = ~AIC, \n    type = 'scatter', mode = 'markers', name = 'Best AIC',\n    marker = list(color = 'red', size = 12, symbol = 'star'),\n    showlegend = FALSE\n  )\n\nplot_bic &lt;- plot_ly(metrics_df, x = ~Model, y = ~BIC, name = 'BIC',\n  type = 'scatter', mode = 'lines+markers',\n  line = list(color = '#ff7f0e', width = 2),\n  marker = list(size = 8, color = '#ff7f0e')) %&gt;% \n  layout(title = \"BIC Trend\", yaxis = list(title = \"BIC\"))\n\nbest_bic &lt;- metrics_df[metrics_df$BIC == min_bic_val, ]\nplot_bic &lt;- plot_bic %&gt;%\n  add_trace(\n    data = best_bic, x = ~Model, y = ~BIC, \n    type = 'scatter', mode = 'markers', name = 'Best BIC',\n    marker = list(color = 'red', size = 12, symbol = 'star'),\n    showlegend = FALSE\n  )\n\nfinal_plot &lt;- subplot(plot_aic, plot_bic, nrows = 2, shareX = TRUE, titleY = TRUE) %&gt;%\n  layout(\n    title = \"Model Selection Criteria: AIC & BIC Trends\",\n    hovermode = \"x unified\",\n    margin = list(t = 50)\n  )\n\nfinal_plot\n\n\n\n\nComparison between AIC and BIC\n\n\nThe graphical analysis of the information criteria highlights a typical divergence found in financial time series modeling.\nAs evidenced by the plot, the AIC criterion, which prioritizes goodness of fit, identifies the ARMA(3,3) as the optimal model (minimum value). Conversely, the BIC criterion, which penalizes model complexity more severely to prevent overfitting, suggests a much more parsimonious model: the ARMA(1,1).\nFaced with these conflicting indications (a complex model vs a simple model), it is not possible to determine a priori which one is superior. To resolve this ambiguity and assess which model generalizes better on unobserved data, we will proceed with an Out-of-Sample validation, computing forecasts and comparing error metrics against actual data.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Return Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/02-return-analysis.html#forecast",
    "href": "qmd/02-return-analysis.html#forecast",
    "title": "2  Return Analysis",
    "section": "2.4 Forecast",
    "text": "2.4 Forecast\nSince the information criteria (AIC and BIC) suggest different models, we proceed with an Out-of-Sample validation to test the actual predictive capacity on data not used for estimation.\nWe split the time series into two subsets:\n\nTraining Set (\\(80\\%\\)): Used to estimate the model parameters.\nTest Set (\\(20\\%\\)): Used to compare forecasts against actual data (h-step-ahead forecast).\n\n\n\nCode\nn_total &lt;- nrow(log_returns)\nn_train &lt;- floor(0.80 * n_total)\n\ntrain_data &lt;- log_returns$LogReturns[1:n_train]\ntest_data &lt;- log_returns$LogReturns[(n_train + 1):n_total]\n\nset.seed(123)\n\nmod_winner_bic &lt;- Arima(train_data, order=c(1,0,1))\nmod_winner_aic &lt;- Arima(train_data, order=c(3,0,3))\nmod_naive &lt;- Arima(train_data, order=c(0,0,0)) \n\nh_steps &lt;- length(test_data)\n\nfc_bic &lt;- forecast(mod_winner_bic, h=h_steps)\nfc_aic &lt;- forecast(mod_winner_aic, h=h_steps)\nfc_naive &lt;- forecast(mod_naive, h=h_steps)\n\n\nThe following plot displays the time series trend and the forecasts generated by the three models over the test period.\n\n\n\n\n\n\nNote\n\n\n\nGiven the stationary nature and high volatility of log-returns, it is expected that medium-to-long-term forecasts will tend to converge rapidly towards the unconditional mean of the process. For this reason we apply method as one-step-ahead and k-step-ahead.\n\n\n\nOne-Steap-AheadFive-Steap-Ahead\n\n\n\n\nCode\nfit_bic_rolling &lt;- Arima(log_returns$LogReturns, model = mod_winner_bic)\none_step_bic &lt;- fitted(fit_bic_rolling)[(n_train + 1):n_total]\n\nfit_aic_rolling &lt;- Arima(log_returns$LogReturns, model = mod_winner_aic)\none_step_aic &lt;- fitted(fit_aic_rolling)[(n_train + 1):n_total]\n\ndates_test  &lt;- log_returns$Date[(n_train + 1):n_total]\n\nfig_roll &lt;- plot_ly(\n  x = dates_test, \n  y = test_data, \n  type = 'scatter', \n  mode = 'lines', \n  name = 'Actual Test Data', \n  line = list(color = 'black', width = 1, dash = 'dot')\n)\n\nfig_roll &lt;- add_trace(\n  fig_roll, \n  x = dates_test, \n  y = as.numeric(one_step_bic), \n  name = 'Rolling ARMA(1,1)', \n  line = list(color = 'blue', width = 1)\n)\n\nfig_roll &lt;- add_trace(\n  fig_roll, \n  x = dates_test, \n  y = as.numeric(one_step_aic), \n  name = 'Rolling ARMA(3,3)', \n  line = list(color = 'red', width = 1)\n)\n\nfig_roll &lt;- layout(\n  fig_roll,\n  title = \"One-Step-Ahead Rolling Forecast (Test Set: 20%)\",\n  xaxis = list(title = \"Date\"),\n  yaxis = list(title = \"Log Return\"),\n  legend = list(orientation = \"h\", x = 0.1, y = -0.2)\n)\n\nfig_roll\n\n\n\n\nComparison One-Step-Ahead Rolling Forecast\n\n\n\n\n\n\nCode\ncalc_k_step_rolling &lt;- function(model_obj, series, n_train, k=5) {\n  n_total &lt;- length(series)\n  test_indices &lt;- (n_train + 1):n_total\n  forecasts &lt;- numeric(length(test_indices))\n  \n  for (i in seq_along(test_indices)) {\n    target_idx &lt;- test_indices[i]\n    origin_idx &lt;- target_idx - k\n    \n    if (origin_idx &gt; 0) {\n      subset_data &lt;- series[1:origin_idx]\n      fit_temp &lt;- Arima(subset_data, model = model_obj)\n      \n      fc_temp &lt;- forecast(fit_temp, h = k)\n      \n      forecasts[i] &lt;- as.numeric(fc_temp$mean[k])\n    } else {\n      forecasts[i] &lt;- NA\n    }\n  }\n  return(forecasts)\n}\n\nk_horizon &lt;- 5\nvec_5step_bic &lt;- calc_k_step_rolling(mod_winner_bic, log_returns$LogReturns, n_train, k = k_horizon)\nvec_5step_aic &lt;- calc_k_step_rolling(mod_winner_aic, log_returns$LogReturns, n_train, k = k_horizon)\n\ndates_test &lt;- log_returns$Date[(n_train + 1):n_total]\n\nfig_roll_5 &lt;- plot_ly(\n  x = dates_test, \n  y = test_data, \n  type = 'scatter', \n  mode = 'lines', \n  name = 'Actual Test Data', \n  line = list(color = 'black', width = 1, dash = 'dot')\n)\n\nfig_roll_5 &lt;- add_trace(\n  fig_roll_5, \n  x = dates_test, \n  y = vec_5step_bic, \n  name = \"Rolling ARMA(1,1)\", \n  line = list(color = 'blue', width = 1.5)\n)\n\nfig_roll_5 &lt;- add_trace(\n  fig_roll_5, \n  x = dates_test, \n  y = vec_5step_aic, \n  name = \"Rolling ARMA(3,3)\", \n  line = list(color = 'red', width = 1.5)\n)\n\nfig_roll_5 &lt;- layout(\n  fig_roll_5,\n  title = \"Five-Step-Ahead Rolling Forecast (Test Set: 20%)\",\n  xaxis = list(title = \"Date\"),\n  yaxis = list(title = \"Log Return\"),\n  legend = list(orientation = \"h\", x = 0.1, y = -0.2)\n)\n\nfig_roll_5\n\n\n\n\nComparison Five-Step-Ahead Rolling Forecast\n\n\n\n\n\nWe evaluate the predictive performance using:\n\nMAE (Mean absolute Error)\nRMSE (Root Mean Squared Error)\nTheil’s U2 index: The ratio between the model’s RMSE and the Naive model’s RMSE.\n\n\\(U&lt;1\\): The model outperforms the benchmark.\n\\(U \\approx 1\\): The model performs equivalently to the benchmark.\n\\(U&gt;1\\): The model performs worse than the benchmark.\n\n\n\n\nCode\nget_metrics_robust &lt;- function(forecast_obj, actuals) {\n  vec_pred &lt;- as.numeric(forecast_obj$mean)\n  vec_obs &lt;- as.numeric(actuals)\n  \n  acc &lt;- accuracy(vec_pred, vec_obs)\n  \n  return(c(RMSE = acc[1, \"RMSE\"], MAE = acc[1, \"MAE\"]))\n}\n\nres_bic &lt;- get_metrics_robust(fc_bic, test_data)\nres_aic &lt;- get_metrics_robust(fc_aic, test_data)\nres_naive &lt;- get_metrics_robust(fc_naive, test_data)\n\nu_bic &lt;- res_bic[\"RMSE\"] / res_naive[\"RMSE\"]\nu_aic &lt;- res_aic[\"RMSE\"] / res_naive[\"RMSE\"]\nu_naive &lt;- 1.0\n\nvalidation_table &lt;- data.frame(\n  Model = c(\"ARMA(1,1) [BIC Winner]\", \"ARMA(3,3) [AIC Winner]\", \"Naive (Benchmark)\"),\n  RMSE = c(res_bic[\"RMSE\"], res_aic[\"RMSE\"], res_naive[\"RMSE\"]),\n  MAE = c(res_bic[\"MAE\"], res_aic[\"MAE\"], res_naive[\"MAE\"]),\n  Theil_U2 = c(u_bic, u_aic, u_naive)\n)\n\ndatatable(validation_table, options = list(dom = 't'), rownames = FALSE)\n\n\n\n\nComparison of out-of-sample error metrics\n\n\nAs highlighted in the table, the Theil’s U2 index for both ARMA models is extremely close to 1. This indicates that the statistical models, despite their complexity, fail to significantly outperform the simple forecast based on the historical mean (Naive Benchmark).\n\n\n\n\n\n\nImportant\n\n\n\nThis result is consistent with the Efficient Market Hypothesis (EMH), according to which past returns contain little to no useful information for predicting future short-term returns, making the series resemble a Random Walk.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Return Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/02-return-analysis.html#conclusion",
    "href": "qmd/02-return-analysis.html#conclusion",
    "title": "2  Return Analysis",
    "section": "2.5 Conclusion",
    "text": "2.5 Conclusion\nThe analysis conducted in this chapter has highlighted the limitations of stationary linear models in forecasting the direction of ASML returns.\nAlthough information criteria (AIC) identified the ARMA(3,3) as a mathematical structure capable of “whitening” the in-sample residuals, the Out-of-Sample validation delivered an unequivocal verdict: a Theil’s U index close to 1 confirms that no ARMA model systematically outperforms the Naive benchmark. This empirical result corroborates the hypothesis that, regarding the conditional mean, returns follow a process closely resembling a Random Walk, rendering trading strategies based solely on past autocorrelation futile.\nHowever, the unpredictability of the mean does not imply a total absence of structure within the series. Visual inspection of the log-returns plot reveals evident volatility clustering: periods of high volatility tend to be followed by high volatility, and periods of calm by calm (a phenomenon known as conditional heteroskedasticity).\nBy assuming constant variance over time (homoskedasticity), ARMA models fail to capture this fundamental characteristic of financial markets. Therefore, in the next chapter, we will shift our focus from predicting the sign of returns to modeling their magnitude (risk) by introducing the GARCH (Generalized AutoRegressive Conditional Heteroskedasticity) family of models.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Return Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/03-volatility-analysis.html",
    "href": "qmd/03-volatility-analysis.html",
    "title": "3  Volatility Analysis",
    "section": "",
    "text": "3.1 Exploratory Volatility Analysis\nIn the previous chapter, we established that ASML returns exhibit a conditional mean behavior closely resembling a Random Walk, making directional forecasting ineffective. However, financial time series are characterized by a “stylized fact” known as volatility clustering: large changes tend to be followed by large changes, and small changes by small changes. This implies that while the sign of the return is unpredictable, its magnitude (risk) follows a recognizable pattern.\nThe objective of this chapter is to model and forecast the conditional variance to quantify the risk associated with the asset. To achieve this, we adopt a structured modeling framework:\nLet’s conduct a visual inspection of the squared log-returns \\((r^2_t)\\) and absolute log-returns \\((|r_t|)\\), while raw returns typically show no correlation (as established in the previous chapter), their squared or absolute versions often exhibit strong persistence.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Volatility Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/03-volatility-analysis.html#exploratory-volatility-analysis",
    "href": "qmd/03-volatility-analysis.html#exploratory-volatility-analysis",
    "title": "3  Volatility Analysis",
    "section": "",
    "text": "Squared ReturnsAbsolute Returns\n\n\n\n\nCode\nfig_sq &lt;- plot_ly(data = log_returns, x = ~Date, y = ~Squared, type = 'scatter',\n  mode = 'lines', name = 'Squared Returns', line = list(color = 'darkred', width = 1))\n\nfig_sq &lt;- layout(\n  fig_sq,\n  title = \"ASML Squared Log-Returns\",\n  xaxis = list(title = \"Date\"),\n  yaxis = list(title = \"Squared Log Return\"),\n  shapes = list(\n    list(\n      type = \"line\",\n      x0 = min(log_returns$Date),\n      x1 = max(log_returns$Date),\n      y0 = 0, \n      y1 = 0,\n      line = list(color = \"black\", width = 1)\n    )\n  )\n)\n\nfig_sq\n\n\n\n\nASML Squared Daily Log-Returns\n\n\n\n\nCode\nacf_sq &lt;- acf(log_returns$Squared, plot = FALSE, lag.max = 30)\npacf_sq &lt;- pacf(log_returns$Squared, plot = FALSE, lag.max = 30)\n\nci &lt;- qnorm((1 + 0.95)/2)/sqrt(length(log_returns$Squared))\n\ndf_acf_sq &lt;- data.frame(\n  lag = as.numeric(acf_sq$lag)[-1],\n  acf = as.numeric(acf_sq$acf)[-1])\n\ndf_pacf_sq &lt;- data.frame(\n  lag = as.numeric(pacf_sq$lag),\n  pacf = as.numeric(pacf_sq$acf))\n\nfig_acf_sq &lt;- plot_ly(df_acf_sq, x = ~lag, y = ~acf, type = 'bar', name = 'ACF',\n  marker = list(color = '#1f77b4')) %&gt;%\n  \n  add_segments(x = min(df_acf_sq$lag), xend = max(df_acf_sq$lag), y = ci, yend = ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %&gt;%\n  \n  add_segments(x = min(df_acf_sq$lag), xend = max(df_acf_sq$lag), y = -ci, yend = -ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %&gt;%\n  \n  layout(yaxis = list(title = \"ACF\"))\n\nfig_pacf_sq &lt;- plot_ly(df_pacf_sq, x = ~lag, y = ~pacf, type = 'bar', name = 'PACF',\n  marker = list(color = '#ff7f0e')) %&gt;%\n  \n  add_segments(x = min(df_pacf_sq$lag), xend = max(df_pacf_sq$lag), y = ci, yend = ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %&gt;%\n  \n  add_segments(x = min(df_pacf_sq$lag), xend = max(df_pacf_sq$lag), y = -ci, yend = -ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %&gt;%\n  \n  layout(yaxis = list(title = \"PACF\"))\n\nsubplot(fig_acf_sq, fig_pacf_sq, nrows = 1, margin = 0.05, titleY = TRUE) %&gt;%\n  layout(title = \"Squared Returns: Autocorrelation & Partial Autocorrelation\", \n  margin = list(t = 50))\n\n\n\n\nSquared Returns ACF and PACF\n\n\n\n\n\n\nCode\nfig_sq &lt;- plot_ly(data = log_returns, x = ~Date, y = ~Abs, type = 'scatter',\n  mode = 'lines', name = 'Absolute Returns', line = list(color = 'darkred', width = 1))\n\nfig_sq &lt;- layout(\n  fig_sq,\n  title = \"ASML Absolute Log-Returns\",\n  xaxis = list(title = \"Date\"),\n  yaxis = list(title = \"Absolute value Log Return\"),\n  shapes = list(\n    list(\n      type = \"line\",\n      x0 = min(log_returns$Date),\n      x1 = max(log_returns$Date),\n      y0 = 0, \n      y1 = 0,\n      line = list(color = \"black\", width = 1)\n    )\n  )\n)\n\nfig_sq\n\n\n\n\nASML Absolute Daily Log-Returns\n\n\n\n\nCode\nacf_abs &lt;- acf(log_returns$Abs, plot = FALSE, lag.max = 30)\npacf_abs &lt;- pacf(log_returns$Abs, plot = FALSE, lag.max = 30)\n\nci &lt;- qnorm((1 + 0.95)/2)/sqrt(length(log_returns$Abs))\n\ndf_acf_abs &lt;- data.frame(\n  lag = as.numeric(acf_abs$lag)[-1],\n  acf = as.numeric(acf_abs$acf)[-1])\n\ndf_pacf_abs &lt;- data.frame(\n  lag = as.numeric(pacf_abs$lag),\n  pacf = as.numeric(pacf_abs$acf))\n\nfig_acf_abs &lt;- plot_ly(df_acf_abs, x = ~lag, y = ~acf, type = 'bar', name = 'ACF',\n  marker = list(color = '#1f77b4')) %&gt;%\n  \n  add_segments(x = min(df_acf_abs$lag), xend = max(df_acf_abs$lag), y = ci, yend = ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %&gt;%\n  \n  add_segments(x = min(df_acf_abs$lag), xend = max(df_acf_abs$lag), y = -ci, yend = -ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %&gt;%\n  \n  layout(yaxis = list(title = \"ACF\"))\n\nfig_pacf_abs &lt;- plot_ly(df_pacf_abs, x = ~lag, y = ~pacf, type = 'bar', name = 'PACF',\n  marker = list(color = '#ff7f0e')) %&gt;%\n  \n  add_segments(x = min(df_pacf_abs$lag), xend = max(df_pacf_abs$lag), y = ci, yend = ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %&gt;%\n  \n  add_segments(x = min(df_pacf_abs$lag), xend = max(df_pacf_abs$lag), y = -ci, yend = -ci, \n  line = list(color = 'red', dash = 'dash', width = 1), showlegend = FALSE) %&gt;%\n  \n  layout(yaxis = list(title = \"PACF\"))\n\nsubplot(fig_acf_abs, fig_pacf_abs, nrows = 1, margin = 0.05, titleY = TRUE) %&gt;%\n  layout(title = \"Absolute Returns: Autocorrelation & Partial Autocorrelation\",\n  margin = list(t = 50))\n\n\n\n\nAbsolute Returns ACF and PACF\n\n\n\n\n\n\nVolatility Clustering: The time series plots of both Squared Log-Returns and Absolute Log-Returns clearly illustrate the phenomenon of volatility clustering. We observe distinct periods of high volatility (large spikes) followed by periods of relative calm. This intermittent bursting behavior violates the assumption of constant variance (homoskedasticity) required by standard linear models.\nPersistence (Long Memory): The analysis of the correlograms provides further evidence. Unlike the ACF of raw returns, the ACF of Squared Returns displays significant positive autocorrelation that decays very slowly. A similar, perhaps even clearer, pattern of slow decay is visible in the ACF of Absolute Returns. This “long memory” indicates that the magnitude of today’s shock has a strong predictive power for future volatility, justifying the use of GARCH-type models.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Volatility Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/03-volatility-analysis.html#formal-testing-for-arch-effects-and-asymmetry",
    "href": "qmd/03-volatility-analysis.html#formal-testing-for-arch-effects-and-asymmetry",
    "title": "3  Volatility Analysis",
    "section": "3.2 Formal Testing for ARCH Effects and Asymmetry",
    "text": "3.2 Formal Testing for ARCH Effects and Asymmetry\nWhile the graphical analysis provides strong intuitive evidence of conditional heteroskedasticity, we must validate these observations using rigorous statistical procedures. Furthermore, visual inspection alone cannot quantify whether the volatility reacts symmetrically to news or if there is a “leverage effect” (where negative returns increase volatility more than positive ones).\nTo address this, we perform the following battery of diagnostic tests:\n\nARCH-LM Test: To formally test the null hypothesis of no ARCH effects in the residuals up to a specified lag.\nAsymmetry Tests: useful for checking the presence of asymmetric volatility (leverage effects)\n\n\nARCH EffectsLeverage Effects\n\n\n\n\nCode\narma_fit &lt;- Arima(log_returns$LogReturns, order = c(1,0,1))\nresiduals_arma &lt;- residuals(arma_fit)\n\nlags_to_test &lt;- c(5, 10, 20)\n\nrun_arch_lm &lt;- function(lag_val) {  \n  lm_test &lt;- ArchTest(residuals_arma, lags = lag_val)\n  \n  return(data.frame(\n    Lag = lag_val,\n    Statistic = lm_test$statistic,\n    P_Value = lm_test$p.value\n  ))\n}\n\narch_results &lt;- do.call(rbind, lapply(lags_to_test, run_arch_lm))\n\narch_display &lt;- arch_results %&gt;%\n  mutate(\n    Conclusion = ifelse(P_Value &lt; 0.05, \"Reject H0\", \"Fail to Reject\"),\n    P_Value = format.pval(P_Value, digits = 3, eps = 0.001)\n  )\n\nknitr::kable(arch_display,\n  caption = \"Engle's ARCH-LM Test for Volatility Clustering\",\n  align = \"c\", row.names = FALSE)\n\n\n\nEngle’s ARCH-LM Test for Volatility Clustering\n\n\nLag\nStatistic\nP_Value\nConclusion\n\n\n\n\n5\n870.6739\n&lt;0.001\nReject H0\n\n\n10\n983.5282\n&lt;0.001\nReject H0\n\n\n20\n1086.0644\n&lt;0.001\nReject H0\n\n\n\n\n\n\n\n\n\nCode\nspec_std &lt;- ugarchspec(\n  variance.model = list(model = \"sGARCH\", garchOrder = c(1, 1)),\n  mean.model = list(armaOrder = c(1, 1), include.mean = TRUE),\n  distribution.model = \"std\"\n)\n\nfit_std &lt;- ugarchfit(spec = spec_std, data = log_returns$LogReturns)\nengle_test &lt;- signbias(fit_std)\n\nengle_df &lt;- data.frame(\n  Test = rownames(engle_test),\n  t_value = engle_test[, 1],\n  Prob = engle_test[, 2],\n  Result = ifelse(engle_test[, 2] &lt; 0.05, \"Asymmetry\", \"Symmetry\")\n)\n\nengle_df$Prob &lt;- format.pval(engle_df$Prob, digits = 3, eps = 0.001)\n\nknitr::kable(engle_df, \n  digits = 4, \n  caption = \"Engle-Ng Tests for Asymmetry (Leverage Effect)\",\n  row.names = FALSE,\n  align = \"c\")\n\n\n\nEngle-Ng Tests for Asymmetry (Leverage Effect)\n\n\nTest\nt_value\nProb\nResult\n\n\n\n\nSign Bias\n0.6572\n0.511\nSymmetry\n\n\nNegative Sign Bias\n0.3227\n0.747\nSymmetry\n\n\nPositive Sign Bias\n0.1283\n0.898\nSymmetry\n\n\nJoint Effect\n1.5848\n0.663\nSymmetry\n\n\n\n\n\n\n\n\nThe preliminary diagnostic phase has already established the presence of significant conditional heteroskedasticity, as the ARCH-LM test strongly rejected the null hypothesis of constant variance. However, regarding the nature of this volatility, the results diverge from the standard market behavior. Contrary to the stylized facts of broad equity indices—where the Leverage Effect typically induces higher volatility during market downturns—the Engle-Ng tests for ASML indicate a symmetric volatility response (\\(H_0\\) is not rejected). This suggests that for ASML, large positive shocks (rallies) generate volatility levels comparable to negative shocks. This behavior is often observed in high-growth technology stocks, where upside volatility is driven by speculative trading and aggressive repricing during expansion cycles.Despite the statistical lack of significant asymmetry, we will proceed with the estimation of asymmetric models (GJR-GARCH and E-GARCH) alongside the standard specification. This ensures a comprehensive model comparison based on Information Criteria (AIC/BIC), verifying whether these models might still offer a superior fit due to their flexibility in handling the error distribution.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Volatility Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/03-volatility-analysis.html#models",
    "href": "qmd/03-volatility-analysis.html#models",
    "title": "3  Volatility Analysis",
    "section": "3.3 Models",
    "text": "3.3 Models\nGiven the evidence of volatility clustering and the potential for non-normal error distributions, we estimate three distinct volatility specifications to identify the model that best describes the data generating process of ASML returns.\nWe compare the following models:\n\nStandard GARCH (sGARCH): Assumes symmetric response to shocks.\nGJR-GARCH: Allows for asymmetric response (leverage effect) targeting the variance directly.\nExponential GARCH (E-GARCH): Models the logarithm of variance, allowing for asymmetry without imposing positivity constraints on coefficients.\n\nTo ensure robustness and account for the “fat tails” observed in the preliminary analysis (Jarque-Bera test), all models are estimated using a Student-t distribution for the innovation process, coupled with the ARMA(1,1) mean equation identified in the previous chapter.\nWe rely on Information Criteria (AIC and BIC) for model selection, where lower values indicate a better trade-off between goodness-of-fit and model parsimony.\n\n\nCode\ncommon_mean &lt;- list(armaOrder = c(1, 1), include.mean = TRUE)\ncommon_dist &lt;- \"std\" \n\nspec_std &lt;- ugarchspec(\n  variance.model = list(model = \"sGARCH\", garchOrder = c(1, 1)),\n  mean.model = common_mean,\n  distribution.model = common_dist\n)\n\nspec_gjr &lt;- ugarchspec(\n  variance.model = list(model = \"gjrGARCH\", garchOrder = c(1, 1)),\n  mean.model = common_mean,\n  distribution.model = common_dist\n)\n\nspec_egarch &lt;- ugarchspec(\n  variance.model = list(model = \"eGARCH\", garchOrder = c(1, 1)),\n  mean.model = common_mean,\n  distribution.model = common_dist\n)\n\nfit_std    &lt;- ugarchfit(spec_std, data = log_returns$LogReturns, solver = \"hybrid\")\nfit_gjr    &lt;- ugarchfit(spec_gjr, data = log_returns$LogReturns, solver = \"hybrid\")\nfit_egarch &lt;- ugarchfit(spec_egarch, data = log_returns$LogReturns, solver = \"hybrid\")\n\ncriteria_df &lt;- data.frame(\n  Model = c(\"sGARCH(1,1)\", \"GJR-GARCH(1,1)\", \"E-GARCH(1,1)\"),\n  AIC = c(infocriteria(fit_std)[1], infocriteria(fit_gjr)[1], infocriteria(fit_egarch)[1]),\n  BIC = c(infocriteria(fit_std)[2], infocriteria(fit_gjr)[2], infocriteria(fit_egarch)[2])\n)\n\ncriteria_df &lt;- criteria_df[order(criteria_df$BIC), ]\n\nknitr::kable(criteria_df, \n  digits = 4, \n  caption = \"Model Selection: AIC and BIC Comparison\",\n  row.names = FALSE,\n  align = \"c\")\n\n\n\nModel Selection: AIC and BIC Comparison\n\n\nModel\nAIC\nBIC\n\n\n\n\nE-GARCH(1,1)\n-4.6872\n-4.6789\n\n\nGJR-GARCH(1,1)\n-4.6820\n-4.6737\n\n\nsGARCH(1,1)\n-4.6718\n-4.6645\n\n\n\nComparison between Symmetric and Asymmetric GARCH",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Volatility Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/03-volatility-analysis.html#forecast",
    "href": "qmd/03-volatility-analysis.html#forecast",
    "title": "3  Volatility Analysis",
    "section": "3.4 Forecast",
    "text": "3.4 Forecast\nSince the information criteria (AIC and BIC) provide an in-sample assessment, we proceed with an Out-of-Sample validation to test the actual predictive capacity on data not used for estimation.\nWe split the time series into two subsets:\n\nTraining Set (\\(80\\%\\)): Used to estimate the GARCH parameters.\nTest Set (\\(20\\%\\)): Used to compare volatility forecasts against the proxy of realized volatility.\n\n\n\nCode\nn_total &lt;- nrow(log_returns)\nn_train &lt;- floor(0.80 * n_total)\nn_test  &lt;- n_total - n_train\n\ncommon_mean &lt;- list(armaOrder = c(1, 1), include.mean = TRUE)\ncommon_dist &lt;- \"std\"\n\nspec_std &lt;- ugarchspec(\n  variance.model = list(model = \"sGARCH\", garchOrder = c(1, 1)), \n  mean.model = common_mean, distribution.model = common_dist)\n\nspec_gjr &lt;- ugarchspec(\n  variance.model = list(model = \"gjrGARCH\", garchOrder = c(1, 1)), \n  mean.model = common_mean, distribution.model = common_dist)\n\nspec_egarch &lt;- ugarchspec(\n  variance.model = list(model = \"eGARCH\", garchOrder = c(1, 1)), \n  mean.model = common_mean, distribution.model = common_dist)\n\nroll_std &lt;- ugarchroll(\n  spec_std, data = log_returns$LogReturns, n.ahead = 1, \n  n.start = n_train, refit.every = 50, refit.window = \"moving\", solver = \"hybrid\")\n\nroll_gjr &lt;- ugarchroll(\n  spec_gjr, data = log_returns$LogReturns, n.ahead = 1, \n  n.start = n_train, refit.every = 50, refit.window = \"moving\", solver = \"hybrid\")\n\nroll_egarch &lt;- ugarchroll(\n  spec_egarch, data = log_returns$LogReturns, n.ahead = 1, \n  n.start = n_train, refit.every = 50, refit.window = \"moving\", solver = \"hybrid\")\n\n\nThe following plot displays the estimated conditional volatility \\((\\hat{\\sigma}_t)\\) generated by the sGARCH, GJR-GARCH and E-GARCH model:\n\n\n\n\n\n\nNote\n\n\n\nUnlike price forecasting, volatility is latent (not directly observable). Therefore, in the following chart, we visually compare the forecasted standard deviation \\(\\hat{\\sigma}_t\\) (colored lines) against the Absolute Returns \\(|r_t|\\) (grey bars). While noisy, absolute returns serve as a standard unbiased proxy for actual market turbulence.\n\n\n\n\nCode\ndf_plot &lt;- as.data.frame(roll_egarch)\n\ndf_plot$Date &lt;- log_returns$Date[(n_train + 1):n_total]\ndf_plot$AbsReturn &lt;- abs(df_plot$Realized)\ndf_plot$Sigma_EGARCH &lt;- df_plot$Sigma\ndf_plot$Sigma_GJR &lt;- as.data.frame(roll_gjr)$Sigma\ndf_plot$Sigma_STD &lt;- as.data.frame(roll_std)$Sigma\n\nfig_unified &lt;- plot_ly(data = df_plot, x = ~Date) %&gt;%\n  \n  add_bars(y = ~AbsReturn, name = 'Abs Returns (|r|)', \n  marker = list(color = 'lightgrey'), opacity = 0.5) %&gt;%\n  \n  add_lines(y = ~Sigma_STD, name = 'sGARCH',\n  line = list(color = 'green', width = 1.5)) %&gt;%\n  \n  add_lines(y = ~Sigma_GJR, name = 'GJR-GARCH',\n  line = list(color = 'steelblue', width = 1.5)) %&gt;%\n  \n  add_lines(y = ~Sigma_EGARCH, name = 'E-GARCH',\n  line = list(color = 'darkorange', width = 1.5)) %&gt;%\n  \n  layout(\n    title = \"Volatility Forecast Comparison (Refit Window: 50 Days)\",\n    yaxis = list(title = \"Volatility (Sigma)\"),\n    xaxis = list(title = \"Date\"),\n    legend = list(orientation = \"h\", x = 0.1, y = -0.2),\n    barmode = \"overlay\",\n    hovermode = \"x unified\"\n  )\n\nfig_unified\n\n\n\n\nVolatility Forecast Comparison: sGARCH vs GJR-GARCH vs E-GARCH\n\n\nWe evaluate the predictive performance using two loss functions, utilizing squared returns \\((r_t^2)\\) as the proxy for latent variance:\n\nRMSE (Root Mean Squared Error): Standard symmetric metric.\nQLIKE (Quasi-Likelihood): Asymmetric loss function that penalizes under-prediction of risk more heavily. This is the preferred metric for volatility model selection.\n\n\n\nCode\ncalc_vol_metrics &lt;- function(roll_obj, name) {\n  df &lt;- as.data.frame(roll_obj)\n  actual_var &lt;- df$Realized^2\n  pred_var   &lt;- df$Sigma^2\n  \n  rmse &lt;- sqrt(mean((actual_var - pred_var)^2))\n  qlike &lt;- mean(log(pred_var) + (actual_var / pred_var))\n  \n  return(c(Model = name, RMSE = rmse, QLIKE = qlike))\n}\n\nm_std &lt;- calc_vol_metrics(roll_std, \"sGARCH(1,1)\")\nm_gjr &lt;- calc_vol_metrics(roll_gjr, \"GJR-GARCH(1,1)\")\nm_eg &lt;- calc_vol_metrics(roll_egarch, \"E-GARCH(1,1)\")\n\nvol_val_table &lt;- data.frame(rbind(m_std, m_gjr, m_eg))\nvol_val_table$RMSE &lt;- as.numeric(vol_val_table$RMSE)\nvol_val_table$QLIKE &lt;- as.numeric(vol_val_table$QLIKE)\nvol_val_table &lt;- vol_val_table[order(vol_val_table$QLIKE), ]\n\ndatatable(vol_val_table, options = list(dom = 't'), rownames = FALSE) %&gt;%\n  formatRound(columns = c('RMSE', 'QLIKE'), digits = 5)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Volatility Analysis</span>"
    ]
  },
  {
    "objectID": "qmd/03-volatility-analysis.html#conclusion",
    "href": "qmd/03-volatility-analysis.html#conclusion",
    "title": "3  Volatility Analysis",
    "section": "3.5 Conclusion",
    "text": "3.5 Conclusion\nThe comprehensive analysis conducted in this chapter—spanning diagnostic tests, in-sample information criteria, and out-of-sample forecasting—provides a clear and robust picture of ASML’s risk profile.\nThe results confirm the standard stylized facts of financial time series regarding the presence of volatility clustering: the rejection of the null hypothesis in the ARCH-LM test proves that ASML’s volatility is not constant but evolves dynamically over time.\nHowever, a distinct and insightful characteristic emerged regarding the nature of this volatility. Contrary to broad equity indices—where the “Leverage Effect” typically induces higher volatility during market downturns—our analysis highlights an unusually low leverage effect. This is supported by multiple converging evidences:\n\nThe Engle-Ng diagnostic tests, which failed to reject the hypothesis of symmetry.\nThe Quantitative Performance Metrics, where both in-sample Information Criteria (AIC/BIC) and Out-of-Sample forecast error measures (RMSE/QLIKE) do not exhibit significant distinctions across specifications. The complex asymmetric models (GJR and E-GARCH) failed to provide a substantial improvement over the standard benchmark, implying that the asymmetry component adds little explanatory power.\n\nThis symmetric behavior, while atypical for the general market, is characteristic of high-growth technology stocks. For ASML, large positive shocks (rallies) generate volatility levels comparable to negative shocks (crashes), likely driven by speculative trading and aggressive repricing during expansion cycles.\nFinal Model Selection: Given the negligible difference in performance metrics, we invoke the Principle of Parsimony and select the sGARCH(1,1) with Student-t distribution as the optimal model. It offers the simplest and most robust representation of the data generating process, correctly capturing the fat tails and volatility clustering without overfitting a leverage effect that is not structurally significant.\nWe conclude this analysis by visually translating the statistical estimates of the selected model into a practical Risk Management metric. The following chart displays the Dynamic Value at Risk (VaR), showing the estimated thresholds for the maximum expected loss at 95% and 99% confidence levels.\n\n\nCode\nsigma_t &lt;- sigma(fit_std)\nmu_t    &lt;- fitted(fit_std)\nshape_param &lt;- coef(fit_std)[\"shape\"]\n\nq_05 &lt;- qdist(distribution = \"std\", p = 0.05, shape = shape_param)\nq_01 &lt;- qdist(distribution = \"std\", p = 0.01, shape = shape_param)\n\nVaR_95 &lt;- mu_t + sigma_t * q_05\nVaR_99 &lt;- mu_t + sigma_t * q_01\n\ndf_risk &lt;- data.frame(\n  Date = log_returns$Date,\n  Returns = log_returns$LogReturns,\n  VaR_95 = as.numeric(VaR_95),\n  VaR_99 = as.numeric(VaR_99)\n)\n\nfig_var &lt;- plot_ly(df_risk, x = ~Date)\n\nfig_var &lt;- add_trace(\n  fig_var, y = ~Returns, type = 'scatter', mode = 'lines',\n  name = 'Log Returns', line = list(color = 'grey', width = 0.5, opacity = 0.5)\n)\n\nfig_var &lt;- add_trace(\n  fig_var, y = ~VaR_95, type = 'scatter', mode = 'lines',\n  name = 'VaR 95% (sGARCH)', line = list(color = 'orange', width = 1.5)\n)\n\nfig_var &lt;- add_trace(\n  fig_var, y = ~VaR_99, type = 'scatter', mode = 'lines',\n  name = 'VaR 99% (sGARCH)', line = list(color = 'darkred', width = 1.5)\n)\n\nfig_var &lt;- layout(\n  fig_var,\n  title = \"Risk Management: ASML Returns vs Dynamic VaR (sGARCH)\",\n  yaxis = list(title = \"Log Return\"),\n  xaxis = list(title = \"Date\"),\n  legend = list(orientation = \"h\", x = 0.1, y = -0.2)\n)\n\nfig_var\n\n\n\n\nValue at Risk (VaR) In-Sample with sGARCH(1,1)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Volatility Analysis</span>"
    ]
  }
]